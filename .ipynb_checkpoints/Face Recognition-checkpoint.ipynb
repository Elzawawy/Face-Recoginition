{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Assignment #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intend to perform face recognition. Face recognition means that for a given image\n",
    "you can tell the subject id. Our database of subject is very simple. It has 40 subjects.\n",
    "Below we will show the needed steps to achieve the goal of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download the dataset and understand the format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "\n",
    "def loadImages(path):\n",
    "    # return array of images\n",
    "    foldersList = listdir(path)\n",
    "    loadedImages = []\n",
    "    for folder in foldersList :\n",
    "        imagesList = listdir(path+folder)\n",
    "        for image in imagesList:\n",
    "            img = PImage.open(path +folder+'/'+ image)\n",
    "            loadedImages.append(img)\n",
    "    return loadedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./orl_faces/\"\n",
    "# your images in an array\n",
    "imgs = loadImages(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate the Data Matrix and the Label vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataMatrix = np.arange(4121600).reshape(400,10304)\n",
    "j=0\n",
    "label = []\n",
    "for i in range(0,400) :\n",
    "    if(i%10 == 0):\n",
    "        j = j+1\n",
    "    dataMatrix[i] = np.array(imgs[i]).flatten()\n",
    "    label.append(j)\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Splitting the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet=np.arange(200*10304).reshape(200,10304)\n",
    "testSet=np.arange(200*10304).reshape(200,10304)\n",
    "trainLabel=[]\n",
    "testLabel=[]\n",
    "j,k=0,0\n",
    "for i in range(0,400):\n",
    "    if(i%2==0):\n",
    "        testSet[j]=dataMatrix[i]\n",
    "        testLabel.append(label[i])\n",
    "        j+=1\n",
    "    else:\n",
    "        trainSet[k]=dataMatrix[i]\n",
    "        trainLabel.append(label[i])\n",
    "        k+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Classification using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMean=np.mean(trainSet,axis=0)\n",
    "centerDataMatrix=trainSet-dataMean\n",
    "covMatrix=(1/200)*(centerDataMatrix @ centerDataMatrix.T)\n",
    "eigVal,eigVectMatrix=np.linalg.eigh(covMatrix)\n",
    "eigVal=np.flip(eigVal,axis=0)\n",
    "eigVectMatrix=np.flip(eigVectMatrix,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDimensionality(eigVal,threshold):\n",
    "    totalDataVariance=np.sum(eigVal)\n",
    "    varianceFraction,numDim,eigValSum=0,1,0\n",
    "    \n",
    "    while(varianceFraction<threshold):\n",
    "        eigValSum+=eigVal[numDim-1]\n",
    "        varianceFraction=eigValSum/totalDataVariance\n",
    "        numDim+=1\n",
    "    return numDim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimAlpha1=computeDimensionality(eigVal,0.8)\n",
    "dimAlpha2=computeDimensionality(eigVal,0.85)\n",
    "dimAlpha3=computeDimensionality(eigVal,0.9)\n",
    "dimAlpha4=computeDimensionality(eigVal,0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "projMat1=eigVectMatrix[:,0:dimAlpha1]\n",
    "projMat2=eigVectMatrix[:,0:dimAlpha2]\n",
    "projMat3=eigVectMatrix[:,0:dimAlpha3]\n",
    "projMat4=eigVectMatrix[:,0:dimAlpha4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedDimTrain1=projMat1.T @ trainSet\n",
    "reducedDimTrain2=projMat2.T @ trainSet\n",
    "reducedDimTrain3=projMat3.T @ trainSet\n",
    "reducedDimTrain4=projMat4.T @ trainSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedDimTest1=projMat1.T @ testSet\n",
    "reducedDimTest2=projMat2.T @ testSet\n",
    "reducedDimTest3=projMat3.T @ testSet\n",
    "reducedDimTest4=projMat4.T @ testSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Classification using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClassList=[]\n",
    "for i in range(0,401):\n",
    "    if(i%10==0 and i!=0):\n",
    "        dataClassList.append(dataMatrix[i-10:i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 47.8,  49.7,  47.2, ...,  49.9,  46.9,  49. ],\n",
       "       [ 35.7,  35.8,  35.8, ...,  84.6,  85.7,  84.4],\n",
       "       [108.3, 109.4, 110.5, ...,  84.7,  80.4,  83.7],\n",
       "       ...,\n",
       "       [121. , 122.4, 121. , ...,  91.4,  96.5,  95.6],\n",
       "       [ 42.5,  43.7,  41.7, ...,  25.6,  23. ,  22. ],\n",
       "       [ 50.5,  51. ,  52.8, ...,  42.8,  44.9,  45.7]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=np.mean(dataClassList,axis=1)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10304, 10304)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withinClassScatterMatrix = np.zeros((10304,10304))\n",
    "for i in range(0,40):\n",
    "    diffMatrix = (dataClassList[i]-mean[i])\n",
    "    withinClassScatterMatrix += diffMatrix.T @ diffMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85.6175, 85.5775, 85.925 , ..., 76.87  , 75.865 , 75.2275])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overallSampleMean = 1/40* np.sum(mean, axis =0)\n",
    "overallSampleMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenClassScatterMatrix = np.zeros((10304,10304))\n",
    "for i in range(0,40):\n",
    "    diffVector = (mean[i]- overallSampleMean)\n",
    "    betweenClassScatterMatrix  += np.outer(diffVector,diffVector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9.84405173e+18+0.j       ,  2.62869630e+18+0.j       ,\n",
       "        -1.13348817e+18+0.j       , ...,  5.69299441e+00+0.j       ,\n",
       "         1.53618240e+01+4.9234791j,  1.53618240e+01-4.9234791j]),\n",
       " array([[-0.01527507+0.j        , -0.07539944+0.j        ,\n",
       "          0.14100898+0.j        , ...,  0.00360501+0.j        ,\n",
       "          0.00137671+0.00314661j,  0.00137671-0.00314661j],\n",
       "        [-0.03872975+0.j        , -0.13755672+0.j        ,\n",
       "          0.07987574+0.j        , ..., -0.0016153 +0.j        ,\n",
       "         -0.00473542-0.00062325j, -0.00473542+0.00062325j],\n",
       "        [-0.04793161+0.j        ,  0.05699947+0.j        ,\n",
       "         -0.03832383+0.j        , ..., -0.00915387+0.j        ,\n",
       "          0.00642665+0.00187265j,  0.00642665-0.00187265j],\n",
       "        ...,\n",
       "        [-0.02589195+0.j        ,  0.02579482+0.j        ,\n",
       "         -0.00969517+0.j        , ...,  0.00365483+0.j        ,\n",
       "         -0.000683  +0.00115062j, -0.000683  -0.00115062j],\n",
       "        [-0.00065264+0.j        , -0.00974578+0.j        ,\n",
       "         -0.0312957 +0.j        , ...,  0.0036042 +0.j        ,\n",
       "         -0.00118132-0.00227108j, -0.00118132+0.00227108j],\n",
       "        [ 0.00164249+0.j        , -0.01748542+0.j        ,\n",
       "         -0.0127678 +0.j        , ..., -0.00088952+0.j        ,\n",
       "         -0.00507045-0.00135268j, -0.00507045+0.00135268j]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(np.linalg.inv(withinClassScatterMatrix)@ betweenClassScatterMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
